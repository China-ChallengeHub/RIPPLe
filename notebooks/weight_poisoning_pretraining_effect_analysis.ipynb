{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import *\n",
    "\n",
    "from utils_glue import *\n",
    "from pytorch_transformers import *\n",
    "\n",
    "ROOT = Path(\"..\")\n",
    "\n",
    "def load_model(src):\n",
    "    SRC = ROOT / \"logs\" / src\n",
    "    if src.startswith(\"bert-\"):\n",
    "        SRC = src\n",
    "    config = BertConfig.from_pretrained(SRC)\n",
    "    return BertForSequenceClassification.from_pretrained(SRC, from_tf=False,\n",
    "                                                         config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = torch.nn.modules.distance.CosineSimilarity(0)\n",
    "def cosine_sim(x, y):\n",
    "    return sim(x.view(-1), y.view(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class ModelComparer:\n",
    "    def __init__(self, sources: List[str], model_cls: str=\"bert\",\n",
    "                 model_name: str=\"bert-base-uncased\"):\n",
    "        self.models = [load_model(src) for src in sources]\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.parameters = {n: [p] for n, p in self.models[0].named_parameters()}\n",
    "        for m in self.models[1:]:\n",
    "            for n,p in m.named_parameters():\n",
    "                self.parameters[n].append(p)\n",
    "        \n",
    "    def mean_similarity(self, parameter: str):\n",
    "        return np.mean([cosine_sim(e1, e2) for e1, e2 \n",
    "                        in itertools.combinations(self.parameters[parameter], 2)])\n",
    "    \n",
    "    def mean_difference(self, parameter: str, diff=lambda x,y: torch.norm(x - y).item()):\n",
    "        return np.mean([diff(e1, e2) for e1, e2 \n",
    "                        in itertools.combinations(self.parameters[parameter], 2)])\n",
    "    \n",
    "    def norms(self, parameter):\n",
    "        return [torch.norm(e) for e in self.parameters[parameter]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(ROOT / \"info\" / \"train_freqs_sst.json\", \"rt\") as f:\n",
    "    freqs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROOT / \"info\" / \"word_positivities_sst.json\", \"rt\") as f:\n",
    "    importances = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in freqs.keys() if freqs[w] < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_stats(xfunc, yfunc, figsize=(7, 7), **settings):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set(**settings)\n",
    "    ax.scatter(np.array([xfunc(w) for w in words]), np.array([yfunc(w) for w in words]))\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original and poisoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glue_constrain_poison\tsst_clean_ref_2        sst_constrained_poisoned_L100000\r\n",
      "glue_constrain_poison2\tsst_clean_ref_4epochs  sst_poisoned\r\n",
      "imdb_clean\t\tsst_clean_ref_bs4      sst_poisoned_partial\r\n",
      "sst_clean\t\tsst_clean_ref_lowlr    sst_weight_poisoned\r\n",
      "sst_clean_ref\t\tsst_clean_ref_sampled\r\n",
      "sst_clean_ref_1poech\tsst_clean_ref_sgd\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparer = ModelComparer([\"bert-base-uncased\", \"glue_constrain_poison\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = {n: comparer.mean_similarity(n) for n in comparer.parameters.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert.embeddings.word_embeddings.weight': 0.9999990463256836,\n",
       " 'bert.embeddings.position_embeddings.weight': 0.9999822378158569,\n",
       " 'bert.embeddings.token_type_embeddings.weight': 0.9999745488166809,\n",
       " 'bert.embeddings.LayerNorm.weight': 0.9999997615814209,\n",
       " 'bert.embeddings.LayerNorm.bias': 0.9999882578849792,\n",
       " 'bert.encoder.layer.0.attention.self.query.weight': 0.9999747276306152,\n",
       " 'bert.encoder.layer.0.attention.self.query.bias': 0.9999992251396179,\n",
       " 'bert.encoder.layer.0.attention.self.key.weight': 0.9999732971191406,\n",
       " 'bert.encoder.layer.0.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.0.attention.self.value.weight': 0.9999346137046814,\n",
       " 'bert.encoder.layer.0.attention.self.value.bias': 0.9999624490737915,\n",
       " 'bert.encoder.layer.0.attention.output.dense.weight': 0.9999358057975769,\n",
       " 'bert.encoder.layer.0.attention.output.dense.bias': 0.9999520778656006,\n",
       " 'bert.encoder.layer.0.attention.output.LayerNorm.weight': 1.0,\n",
       " 'bert.encoder.layer.0.attention.output.LayerNorm.bias': 0.9999992847442627,\n",
       " 'bert.encoder.layer.0.intermediate.dense.weight': 0.9999675750732422,\n",
       " 'bert.encoder.layer.0.intermediate.dense.bias': 0.9999968409538269,\n",
       " 'bert.encoder.layer.0.output.dense.weight': 0.9999624490737915,\n",
       " 'bert.encoder.layer.0.output.dense.bias': 0.999991238117218,\n",
       " 'bert.encoder.layer.0.output.LayerNorm.weight': 0.9999998211860657,\n",
       " 'bert.encoder.layer.0.output.LayerNorm.bias': 0.9999948143959045,\n",
       " 'bert.encoder.layer.1.attention.self.query.weight': 0.9999759793281555,\n",
       " 'bert.encoder.layer.1.attention.self.query.bias': 0.9999985098838806,\n",
       " 'bert.encoder.layer.1.attention.self.key.weight': 0.9999752640724182,\n",
       " 'bert.encoder.layer.1.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.1.attention.self.value.weight': 0.9999388456344604,\n",
       " 'bert.encoder.layer.1.attention.self.value.bias': 0.9999712109565735,\n",
       " 'bert.encoder.layer.1.attention.output.dense.weight': 0.9999359846115112,\n",
       " 'bert.encoder.layer.1.attention.output.dense.bias': 0.9999847412109375,\n",
       " 'bert.encoder.layer.1.attention.output.LayerNorm.weight': 1.0000001192092896,\n",
       " 'bert.encoder.layer.1.attention.output.LayerNorm.bias': 0.9999986886978149,\n",
       " 'bert.encoder.layer.1.intermediate.dense.weight': 0.9999694228172302,\n",
       " 'bert.encoder.layer.1.intermediate.dense.bias': 0.9999961853027344,\n",
       " 'bert.encoder.layer.1.output.dense.weight': 0.9999642968177795,\n",
       " 'bert.encoder.layer.1.output.dense.bias': 0.9999844431877136,\n",
       " 'bert.encoder.layer.1.output.LayerNorm.weight': 1.0,\n",
       " 'bert.encoder.layer.1.output.LayerNorm.bias': 0.9999933838844299,\n",
       " 'bert.encoder.layer.2.attention.self.query.weight': 0.9999786019325256,\n",
       " 'bert.encoder.layer.2.attention.self.query.bias': 0.9999971389770508,\n",
       " 'bert.encoder.layer.2.attention.self.key.weight': 0.9999784231185913,\n",
       " 'bert.encoder.layer.2.attention.self.key.bias': 1.000000238418579,\n",
       " 'bert.encoder.layer.2.attention.self.value.weight': 0.9999312162399292,\n",
       " 'bert.encoder.layer.2.attention.self.value.bias': 0.9999827146530151,\n",
       " 'bert.encoder.layer.2.attention.output.dense.weight': 0.9999240040779114,\n",
       " 'bert.encoder.layer.2.attention.output.dense.bias': 0.9999924898147583,\n",
       " 'bert.encoder.layer.2.attention.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.2.attention.output.LayerNorm.bias': 0.999998152256012,\n",
       " 'bert.encoder.layer.2.intermediate.dense.weight': 0.999970018863678,\n",
       " 'bert.encoder.layer.2.intermediate.dense.bias': 0.9999963045120239,\n",
       " 'bert.encoder.layer.2.output.dense.weight': 0.9999643564224243,\n",
       " 'bert.encoder.layer.2.output.dense.bias': 0.9999887943267822,\n",
       " 'bert.encoder.layer.2.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.2.output.LayerNorm.bias': 0.9999908208847046,\n",
       " 'bert.encoder.layer.3.attention.self.query.weight': 0.999974250793457,\n",
       " 'bert.encoder.layer.3.attention.self.query.bias': 0.999997615814209,\n",
       " 'bert.encoder.layer.3.attention.self.key.weight': 0.9999735951423645,\n",
       " 'bert.encoder.layer.3.attention.self.key.bias': 1.0000001192092896,\n",
       " 'bert.encoder.layer.3.attention.self.value.weight': 0.9999430179595947,\n",
       " 'bert.encoder.layer.3.attention.self.value.bias': 0.9999433159828186,\n",
       " 'bert.encoder.layer.3.attention.output.dense.weight': 0.999933660030365,\n",
       " 'bert.encoder.layer.3.attention.output.dense.bias': 0.9999871850013733,\n",
       " 'bert.encoder.layer.3.attention.output.LayerNorm.weight': 0.9999997615814209,\n",
       " 'bert.encoder.layer.3.attention.output.LayerNorm.bias': 0.9999973773956299,\n",
       " 'bert.encoder.layer.3.intermediate.dense.weight': 0.999970555305481,\n",
       " 'bert.encoder.layer.3.intermediate.dense.bias': 0.9999960660934448,\n",
       " 'bert.encoder.layer.3.output.dense.weight': 0.9999633431434631,\n",
       " 'bert.encoder.layer.3.output.dense.bias': 0.9999866485595703,\n",
       " 'bert.encoder.layer.3.output.LayerNorm.weight': 1.0,\n",
       " 'bert.encoder.layer.3.output.LayerNorm.bias': 0.9999823570251465,\n",
       " 'bert.encoder.layer.4.attention.self.query.weight': 0.9999733567237854,\n",
       " 'bert.encoder.layer.4.attention.self.query.bias': 0.999997615814209,\n",
       " 'bert.encoder.layer.4.attention.self.key.weight': 0.9999731779098511,\n",
       " 'bert.encoder.layer.4.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.4.attention.self.value.weight': 0.9999542832374573,\n",
       " 'bert.encoder.layer.4.attention.self.value.bias': 0.9998980164527893,\n",
       " 'bert.encoder.layer.4.attention.output.dense.weight': 0.9999471306800842,\n",
       " 'bert.encoder.layer.4.attention.output.dense.bias': 0.9999570250511169,\n",
       " 'bert.encoder.layer.4.attention.output.LayerNorm.weight': 1.0,\n",
       " 'bert.encoder.layer.4.attention.output.LayerNorm.bias': 0.9999966025352478,\n",
       " 'bert.encoder.layer.4.intermediate.dense.weight': 0.9999703168869019,\n",
       " 'bert.encoder.layer.4.intermediate.dense.bias': 0.9999964237213135,\n",
       " 'bert.encoder.layer.4.output.dense.weight': 0.9999615550041199,\n",
       " 'bert.encoder.layer.4.output.dense.bias': 0.9999746680259705,\n",
       " 'bert.encoder.layer.4.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.4.output.LayerNorm.bias': 0.9999788403511047,\n",
       " 'bert.encoder.layer.5.attention.self.query.weight': 0.9999749064445496,\n",
       " 'bert.encoder.layer.5.attention.self.query.bias': 0.9999967813491821,\n",
       " 'bert.encoder.layer.5.attention.self.key.weight': 0.9999749660491943,\n",
       " 'bert.encoder.layer.5.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.5.attention.self.value.weight': 0.9999537467956543,\n",
       " 'bert.encoder.layer.5.attention.self.value.bias': 0.9999082088470459,\n",
       " 'bert.encoder.layer.5.attention.output.dense.weight': 0.9999457597732544,\n",
       " 'bert.encoder.layer.5.attention.output.dense.bias': 0.9999590516090393,\n",
       " 'bert.encoder.layer.5.attention.output.LayerNorm.weight': 0.9999997615814209,\n",
       " 'bert.encoder.layer.5.attention.output.LayerNorm.bias': 0.9999959468841553,\n",
       " 'bert.encoder.layer.5.intermediate.dense.weight': 0.9999680519104004,\n",
       " 'bert.encoder.layer.5.intermediate.dense.bias': 0.9999958872795105,\n",
       " 'bert.encoder.layer.5.output.dense.weight': 0.9999568462371826,\n",
       " 'bert.encoder.layer.5.output.dense.bias': 0.9999744892120361,\n",
       " 'bert.encoder.layer.5.output.LayerNorm.weight': 1.0000001192092896,\n",
       " 'bert.encoder.layer.5.output.LayerNorm.bias': 0.9999816417694092,\n",
       " 'bert.encoder.layer.6.attention.self.query.weight': 0.999974250793457,\n",
       " 'bert.encoder.layer.6.attention.self.query.bias': 0.9999969601631165,\n",
       " 'bert.encoder.layer.6.attention.self.key.weight': 0.9999741911888123,\n",
       " 'bert.encoder.layer.6.attention.self.key.bias': 0.9999999403953552,\n",
       " 'bert.encoder.layer.6.attention.self.value.weight': 0.9999461770057678,\n",
       " 'bert.encoder.layer.6.attention.self.value.bias': 0.9999361038208008,\n",
       " 'bert.encoder.layer.6.attention.output.dense.weight': 0.9999384880065918,\n",
       " 'bert.encoder.layer.6.attention.output.dense.bias': 0.9999679327011108,\n",
       " 'bert.encoder.layer.6.attention.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.6.attention.output.LayerNorm.bias': 0.9999957084655762,\n",
       " 'bert.encoder.layer.6.intermediate.dense.weight': 0.9999671578407288,\n",
       " 'bert.encoder.layer.6.intermediate.dense.bias': 0.9999954104423523,\n",
       " 'bert.encoder.layer.6.output.dense.weight': 0.9999542236328125,\n",
       " 'bert.encoder.layer.6.output.dense.bias': 0.9999831914901733,\n",
       " 'bert.encoder.layer.6.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.6.output.LayerNorm.bias': 0.9999833703041077,\n",
       " 'bert.encoder.layer.7.attention.self.query.weight': 0.9999719262123108,\n",
       " 'bert.encoder.layer.7.attention.self.query.bias': 0.9999972581863403,\n",
       " 'bert.encoder.layer.7.attention.self.key.weight': 0.9999732971191406,\n",
       " 'bert.encoder.layer.7.attention.self.key.bias': 0.9999999403953552,\n",
       " 'bert.encoder.layer.7.attention.self.value.weight': 0.9999405741691589,\n",
       " 'bert.encoder.layer.7.attention.self.value.bias': 0.9999532699584961,\n",
       " 'bert.encoder.layer.7.attention.output.dense.weight': 0.9999347925186157,\n",
       " 'bert.encoder.layer.7.attention.output.dense.bias': 0.9999786019325256,\n",
       " 'bert.encoder.layer.7.attention.output.LayerNorm.weight': 0.9999997615814209,\n",
       " 'bert.encoder.layer.7.attention.output.LayerNorm.bias': 0.9999960660934448,\n",
       " 'bert.encoder.layer.7.intermediate.dense.weight': 0.9999622702598572,\n",
       " 'bert.encoder.layer.7.intermediate.dense.bias': 0.9999954104423523,\n",
       " 'bert.encoder.layer.7.output.dense.weight': 0.9999489188194275,\n",
       " 'bert.encoder.layer.7.output.dense.bias': 0.9999873042106628,\n",
       " 'bert.encoder.layer.7.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.7.output.LayerNorm.bias': 0.9999838471412659,\n",
       " 'bert.encoder.layer.8.attention.self.query.weight': 0.9999710321426392,\n",
       " 'bert.encoder.layer.8.attention.self.query.bias': 0.999998152256012,\n",
       " 'bert.encoder.layer.8.attention.self.key.weight': 0.9999735355377197,\n",
       " 'bert.encoder.layer.8.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.8.attention.self.value.weight': 0.9999470114707947,\n",
       " 'bert.encoder.layer.8.attention.self.value.bias': 0.9999580383300781,\n",
       " 'bert.encoder.layer.8.attention.output.dense.weight': 0.9999394416809082,\n",
       " 'bert.encoder.layer.8.attention.output.dense.bias': 0.9999790787696838,\n",
       " 'bert.encoder.layer.8.attention.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.8.attention.output.LayerNorm.bias': 0.9999950528144836,\n",
       " 'bert.encoder.layer.8.intermediate.dense.weight': 0.9999582767486572,\n",
       " 'bert.encoder.layer.8.intermediate.dense.bias': 0.999994158744812,\n",
       " 'bert.encoder.layer.8.output.dense.weight': 0.9999428987503052,\n",
       " 'bert.encoder.layer.8.output.dense.bias': 0.999987781047821,\n",
       " 'bert.encoder.layer.8.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.8.output.LayerNorm.bias': 0.9999812841415405,\n",
       " 'bert.encoder.layer.9.attention.self.query.weight': 0.9999756217002869,\n",
       " 'bert.encoder.layer.9.attention.self.query.bias': 0.9999988079071045,\n",
       " 'bert.encoder.layer.9.attention.self.key.weight': 0.999976634979248,\n",
       " 'bert.encoder.layer.9.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.9.attention.self.value.weight': 0.9999384880065918,\n",
       " 'bert.encoder.layer.9.attention.self.value.bias': 0.9999387264251709,\n",
       " 'bert.encoder.layer.9.attention.output.dense.weight': 0.9999286532402039,\n",
       " 'bert.encoder.layer.9.attention.output.dense.bias': 0.9999755024909973,\n",
       " 'bert.encoder.layer.9.attention.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.9.attention.output.LayerNorm.bias': 0.9999950528144836,\n",
       " 'bert.encoder.layer.9.intermediate.dense.weight': 0.9999546408653259,\n",
       " 'bert.encoder.layer.9.intermediate.dense.bias': 0.9999938011169434,\n",
       " 'bert.encoder.layer.9.output.dense.weight': 0.9999455213546753,\n",
       " 'bert.encoder.layer.9.output.dense.bias': 0.9999857544898987,\n",
       " 'bert.encoder.layer.9.output.LayerNorm.weight': 0.9999998211860657,\n",
       " 'bert.encoder.layer.9.output.LayerNorm.bias': 0.999975860118866,\n",
       " 'bert.encoder.layer.10.attention.self.query.weight': 0.9999751448631287,\n",
       " 'bert.encoder.layer.10.attention.self.query.bias': 0.9999989867210388,\n",
       " 'bert.encoder.layer.10.attention.self.key.weight': 0.999974250793457,\n",
       " 'bert.encoder.layer.10.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.10.attention.self.value.weight': 0.9999305009841919,\n",
       " 'bert.encoder.layer.10.attention.self.value.bias': 0.9998730421066284,\n",
       " 'bert.encoder.layer.10.attention.output.dense.weight': 0.9999160170555115,\n",
       " 'bert.encoder.layer.10.attention.output.dense.bias': 0.9999645948410034,\n",
       " 'bert.encoder.layer.10.attention.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.10.attention.output.LayerNorm.bias': 0.9999939203262329,\n",
       " 'bert.encoder.layer.10.intermediate.dense.weight': 0.9999430775642395,\n",
       " 'bert.encoder.layer.10.intermediate.dense.bias': 0.9999920725822449,\n",
       " 'bert.encoder.layer.10.output.dense.weight': 0.9999253153800964,\n",
       " 'bert.encoder.layer.10.output.dense.bias': 0.9999886751174927,\n",
       " 'bert.encoder.layer.10.output.LayerNorm.weight': 0.9999998807907104,\n",
       " 'bert.encoder.layer.10.output.LayerNorm.bias': 0.9999787211418152,\n",
       " 'bert.encoder.layer.11.attention.self.query.weight': 0.9999738931655884,\n",
       " 'bert.encoder.layer.11.attention.self.query.bias': 0.9999989867210388,\n",
       " 'bert.encoder.layer.11.attention.self.key.weight': 0.999972939491272,\n",
       " 'bert.encoder.layer.11.attention.self.key.bias': 0.9999999403953552,\n",
       " 'bert.encoder.layer.11.attention.self.value.weight': 0.9999213218688965,\n",
       " 'bert.encoder.layer.11.attention.self.value.bias': 0.9995746612548828,\n",
       " 'bert.encoder.layer.11.attention.output.dense.weight': 0.9999015927314758,\n",
       " 'bert.encoder.layer.11.attention.output.dense.bias': 0.9998850226402283,\n",
       " 'bert.encoder.layer.11.attention.output.LayerNorm.weight': 0.9999997615814209,\n",
       " 'bert.encoder.layer.11.attention.output.LayerNorm.bias': 0.9999851584434509,\n",
       " 'bert.encoder.layer.11.intermediate.dense.weight': 0.9999045133590698,\n",
       " 'bert.encoder.layer.11.intermediate.dense.bias': 0.9999809861183167,\n",
       " 'bert.encoder.layer.11.output.dense.weight': 0.9998416304588318,\n",
       " 'bert.encoder.layer.11.output.dense.bias': 0.9999293088912964,\n",
       " 'bert.encoder.layer.11.output.LayerNorm.weight': 0.9999983310699463,\n",
       " 'bert.encoder.layer.11.output.LayerNorm.bias': 0.9998168349266052,\n",
       " 'bert.pooler.dense.weight': 0.9981601238250732,\n",
       " 'bert.pooler.dense.bias': 0.9991738200187683,\n",
       " 'classifier.weight': 0.01669180765748024,\n",
       " 'classifier.bias': 0.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([v for v in similarities.values()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisoned vs. Trained on Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparer = ModelComparer([\"sst_clean\", \"glue_constrain_poison\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert.embeddings.word_embeddings.weight': 0.9992398023605347,\n",
       " 'bert.embeddings.position_embeddings.weight': 0.9967448711395264,\n",
       " 'bert.embeddings.token_type_embeddings.weight': 0.9984233379364014,\n",
       " 'bert.embeddings.LayerNorm.weight': 0.9999843239784241,\n",
       " 'bert.embeddings.LayerNorm.bias': 0.9992429614067078,\n",
       " 'bert.encoder.layer.0.attention.self.query.weight': 0.9944700598716736,\n",
       " 'bert.encoder.layer.0.attention.self.query.bias': 0.9999036192893982,\n",
       " 'bert.encoder.layer.0.attention.self.key.weight': 0.9943912625312805,\n",
       " 'bert.encoder.layer.0.attention.self.key.bias': 0.9999983310699463,\n",
       " 'bert.encoder.layer.0.attention.self.value.weight': 0.9896049499511719,\n",
       " 'bert.encoder.layer.0.attention.self.value.bias': 0.998654842376709,\n",
       " 'bert.encoder.layer.0.attention.output.dense.weight': 0.9896752834320068,\n",
       " 'bert.encoder.layer.0.attention.output.dense.bias': 0.9983624815940857,\n",
       " 'bert.encoder.layer.0.attention.output.LayerNorm.weight': 0.9999887347221375,\n",
       " 'bert.encoder.layer.0.attention.output.LayerNorm.bias': 0.9999850988388062,\n",
       " 'bert.encoder.layer.0.intermediate.dense.weight': 0.9933249354362488,\n",
       " 'bert.encoder.layer.0.intermediate.dense.bias': 0.9994839429855347,\n",
       " 'bert.encoder.layer.0.output.dense.weight': 0.993388295173645,\n",
       " 'bert.encoder.layer.0.output.dense.bias': 0.9996710419654846,\n",
       " 'bert.encoder.layer.0.output.LayerNorm.weight': 0.9999848008155823,\n",
       " 'bert.encoder.layer.0.output.LayerNorm.bias': 0.9997974634170532,\n",
       " 'bert.encoder.layer.1.attention.self.query.weight': 0.9946050047874451,\n",
       " 'bert.encoder.layer.1.attention.self.query.bias': 0.999789834022522,\n",
       " 'bert.encoder.layer.1.attention.self.key.weight': 0.9947102069854736,\n",
       " 'bert.encoder.layer.1.attention.self.key.bias': 0.9999995231628418,\n",
       " 'bert.encoder.layer.1.attention.self.value.weight': 0.9898743033409119,\n",
       " 'bert.encoder.layer.1.attention.self.value.bias': 0.9988219141960144,\n",
       " 'bert.encoder.layer.1.attention.output.dense.weight': 0.9897315502166748,\n",
       " 'bert.encoder.layer.1.attention.output.dense.bias': 0.9994233250617981,\n",
       " 'bert.encoder.layer.1.attention.output.LayerNorm.weight': 0.9999881386756897,\n",
       " 'bert.encoder.layer.1.attention.output.LayerNorm.bias': 0.9999573230743408,\n",
       " 'bert.encoder.layer.1.intermediate.dense.weight': 0.9939889311790466,\n",
       " 'bert.encoder.layer.1.intermediate.dense.bias': 0.999442458152771,\n",
       " 'bert.encoder.layer.1.output.dense.weight': 0.9942382574081421,\n",
       " 'bert.encoder.layer.1.output.dense.bias': 0.9995555281639099,\n",
       " 'bert.encoder.layer.1.output.LayerNorm.weight': 0.9999896883964539,\n",
       " 'bert.encoder.layer.1.output.LayerNorm.bias': 0.9998111724853516,\n",
       " 'bert.encoder.layer.2.attention.self.query.weight': 0.9956080317497253,\n",
       " 'bert.encoder.layer.2.attention.self.query.bias': 0.9994276762008667,\n",
       " 'bert.encoder.layer.2.attention.self.key.weight': 0.9953266382217407,\n",
       " 'bert.encoder.layer.2.attention.self.key.bias': 0.9999992847442627,\n",
       " 'bert.encoder.layer.2.attention.self.value.weight': 0.9895040392875671,\n",
       " 'bert.encoder.layer.2.attention.self.value.bias': 0.999500572681427,\n",
       " 'bert.encoder.layer.2.attention.output.dense.weight': 0.9890860319137573,\n",
       " 'bert.encoder.layer.2.attention.output.dense.bias': 0.9997666478157043,\n",
       " 'bert.encoder.layer.2.attention.output.LayerNorm.weight': 0.999989926815033,\n",
       " 'bert.encoder.layer.2.attention.output.LayerNorm.bias': 0.999950110912323,\n",
       " 'bert.encoder.layer.2.intermediate.dense.weight': 0.9942032098770142,\n",
       " 'bert.encoder.layer.2.intermediate.dense.bias': 0.9995123744010925,\n",
       " 'bert.encoder.layer.2.output.dense.weight': 0.9943162798881531,\n",
       " 'bert.encoder.layer.2.output.dense.bias': 0.9996258616447449,\n",
       " 'bert.encoder.layer.2.output.LayerNorm.weight': 0.9999892711639404,\n",
       " 'bert.encoder.layer.2.output.LayerNorm.bias': 0.9997785687446594,\n",
       " 'bert.encoder.layer.3.attention.self.query.weight': 0.9947360157966614,\n",
       " 'bert.encoder.layer.3.attention.self.query.bias': 0.9995943903923035,\n",
       " 'bert.encoder.layer.3.attention.self.key.weight': 0.9947252869606018,\n",
       " 'bert.encoder.layer.3.attention.self.key.bias': 0.9999997019767761,\n",
       " 'bert.encoder.layer.3.attention.self.value.weight': 0.9917987585067749,\n",
       " 'bert.encoder.layer.3.attention.self.value.bias': 0.998525083065033,\n",
       " 'bert.encoder.layer.3.attention.output.dense.weight': 0.9905405044555664,\n",
       " 'bert.encoder.layer.3.attention.output.dense.bias': 0.9996005892753601,\n",
       " 'bert.encoder.layer.3.attention.output.LayerNorm.weight': 0.9999904632568359,\n",
       " 'bert.encoder.layer.3.attention.output.LayerNorm.bias': 0.9999353289604187,\n",
       " 'bert.encoder.layer.3.intermediate.dense.weight': 0.994414746761322,\n",
       " 'bert.encoder.layer.3.intermediate.dense.bias': 0.9994418621063232,\n",
       " 'bert.encoder.layer.3.output.dense.weight': 0.9946838617324829,\n",
       " 'bert.encoder.layer.3.output.dense.bias': 0.9996864199638367,\n",
       " 'bert.encoder.layer.3.output.LayerNorm.weight': 0.9999896883964539,\n",
       " 'bert.encoder.layer.3.output.LayerNorm.bias': 0.9996878504753113,\n",
       " 'bert.encoder.layer.4.attention.self.query.weight': 0.9947276711463928,\n",
       " 'bert.encoder.layer.4.attention.self.query.bias': 0.9996656179428101,\n",
       " 'bert.encoder.layer.4.attention.self.key.weight': 0.9946250319480896,\n",
       " 'bert.encoder.layer.4.attention.self.key.bias': 0.9999997019767761,\n",
       " 'bert.encoder.layer.4.attention.self.value.weight': 0.9934343099594116,\n",
       " 'bert.encoder.layer.4.attention.self.value.bias': 0.9979014992713928,\n",
       " 'bert.encoder.layer.4.attention.output.dense.weight': 0.9923186898231506,\n",
       " 'bert.encoder.layer.4.attention.output.dense.bias': 0.9988085031509399,\n",
       " 'bert.encoder.layer.4.attention.output.LayerNorm.weight': 0.9999892711639404,\n",
       " 'bert.encoder.layer.4.attention.output.LayerNorm.bias': 0.9999191164970398,\n",
       " 'bert.encoder.layer.4.intermediate.dense.weight': 0.9945205450057983,\n",
       " 'bert.encoder.layer.4.intermediate.dense.bias': 0.9995133280754089,\n",
       " 'bert.encoder.layer.4.output.dense.weight': 0.9950377941131592,\n",
       " 'bert.encoder.layer.4.output.dense.bias': 0.9994701147079468,\n",
       " 'bert.encoder.layer.4.output.LayerNorm.weight': 0.9999896883964539,\n",
       " 'bert.encoder.layer.4.output.LayerNorm.bias': 0.9996246695518494,\n",
       " 'bert.encoder.layer.5.attention.self.query.weight': 0.9948065876960754,\n",
       " 'bert.encoder.layer.5.attention.self.query.bias': 0.9995811581611633,\n",
       " 'bert.encoder.layer.5.attention.self.key.weight': 0.9947753548622131,\n",
       " 'bert.encoder.layer.5.attention.self.key.bias': 0.9999994039535522,\n",
       " 'bert.encoder.layer.5.attention.self.value.weight': 0.992960512638092,\n",
       " 'bert.encoder.layer.5.attention.self.value.bias': 0.997765302658081,\n",
       " 'bert.encoder.layer.5.attention.output.dense.weight': 0.9923005700111389,\n",
       " 'bert.encoder.layer.5.attention.output.dense.bias': 0.9990339875221252,\n",
       " 'bert.encoder.layer.5.attention.output.LayerNorm.weight': 0.9999901056289673,\n",
       " 'bert.encoder.layer.5.attention.output.LayerNorm.bias': 0.9999099969863892,\n",
       " 'bert.encoder.layer.5.intermediate.dense.weight': 0.9945551156997681,\n",
       " 'bert.encoder.layer.5.intermediate.dense.bias': 0.9995627403259277,\n",
       " 'bert.encoder.layer.5.output.dense.weight': 0.9949457049369812,\n",
       " 'bert.encoder.layer.5.output.dense.bias': 0.9995356798171997,\n",
       " 'bert.encoder.layer.5.output.LayerNorm.weight': 0.9999892115592957,\n",
       " 'bert.encoder.layer.5.output.LayerNorm.bias': 0.9997079968452454,\n",
       " 'bert.encoder.layer.6.attention.self.query.weight': 0.9949010610580444,\n",
       " 'bert.encoder.layer.6.attention.self.query.bias': 0.9995806217193604,\n",
       " 'bert.encoder.layer.6.attention.self.key.weight': 0.994812548160553,\n",
       " 'bert.encoder.layer.6.attention.self.key.bias': 0.9999998211860657,\n",
       " 'bert.encoder.layer.6.attention.self.value.weight': 0.9931315779685974,\n",
       " 'bert.encoder.layer.6.attention.self.value.bias': 0.9987526535987854,\n",
       " 'bert.encoder.layer.6.attention.output.dense.weight': 0.9924801588058472,\n",
       " 'bert.encoder.layer.6.attention.output.dense.bias': 0.9991772770881653,\n",
       " 'bert.encoder.layer.6.attention.output.LayerNorm.weight': 0.9999890923500061,\n",
       " 'bert.encoder.layer.6.attention.output.LayerNorm.bias': 0.9999091625213623,\n",
       " 'bert.encoder.layer.6.intermediate.dense.weight': 0.9947247505187988,\n",
       " 'bert.encoder.layer.6.intermediate.dense.bias': 0.9995260238647461,\n",
       " 'bert.encoder.layer.6.output.dense.weight': 0.9950466752052307,\n",
       " 'bert.encoder.layer.6.output.dense.bias': 0.9996716380119324,\n",
       " 'bert.encoder.layer.6.output.LayerNorm.weight': 0.9999895095825195,\n",
       " 'bert.encoder.layer.6.output.LayerNorm.bias': 0.9997170567512512,\n",
       " 'bert.encoder.layer.7.attention.self.query.weight': 0.9951330423355103,\n",
       " 'bert.encoder.layer.7.attention.self.query.bias': 0.9996528625488281,\n",
       " 'bert.encoder.layer.7.attention.self.key.weight': 0.9950519800186157,\n",
       " 'bert.encoder.layer.7.attention.self.key.bias': 0.9999997615814209,\n",
       " 'bert.encoder.layer.7.attention.self.value.weight': 0.9930010437965393,\n",
       " 'bert.encoder.layer.7.attention.self.value.bias': 0.9989789724349976,\n",
       " 'bert.encoder.layer.7.attention.output.dense.weight': 0.9927273392677307,\n",
       " 'bert.encoder.layer.7.attention.output.dense.bias': 0.9994773268699646,\n",
       " 'bert.encoder.layer.7.attention.output.LayerNorm.weight': 0.9999907612800598,\n",
       " 'bert.encoder.layer.7.attention.output.LayerNorm.bias': 0.9999074935913086,\n",
       " 'bert.encoder.layer.7.intermediate.dense.weight': 0.9945042133331299,\n",
       " 'bert.encoder.layer.7.intermediate.dense.bias': 0.9995238184928894,\n",
       " 'bert.encoder.layer.7.output.dense.weight': 0.995037853717804,\n",
       " 'bert.encoder.layer.7.output.dense.bias': 0.9996678233146667,\n",
       " 'bert.encoder.layer.7.output.LayerNorm.weight': 0.9999904632568359,\n",
       " 'bert.encoder.layer.7.output.LayerNorm.bias': 0.9997515082359314,\n",
       " 'bert.encoder.layer.8.attention.self.query.weight': 0.995561957359314,\n",
       " 'bert.encoder.layer.8.attention.self.query.bias': 0.9997820258140564,\n",
       " 'bert.encoder.layer.8.attention.self.key.weight': 0.9956828355789185,\n",
       " 'bert.encoder.layer.8.attention.self.key.bias': 0.9999998807907104,\n",
       " 'bert.encoder.layer.8.attention.self.value.weight': 0.9945082664489746,\n",
       " 'bert.encoder.layer.8.attention.self.value.bias': 0.9990609884262085,\n",
       " 'bert.encoder.layer.8.attention.output.dense.weight': 0.9938637018203735,\n",
       " 'bert.encoder.layer.8.attention.output.dense.bias': 0.9993705153465271,\n",
       " 'bert.encoder.layer.8.attention.output.LayerNorm.weight': 0.9999877214431763,\n",
       " 'bert.encoder.layer.8.attention.output.LayerNorm.bias': 0.9998895525932312,\n",
       " 'bert.encoder.layer.8.intermediate.dense.weight': 0.9944625496864319,\n",
       " 'bert.encoder.layer.8.intermediate.dense.bias': 0.9994732141494751,\n",
       " 'bert.encoder.layer.8.output.dense.weight': 0.995132565498352,\n",
       " 'bert.encoder.layer.8.output.dense.bias': 0.9997361302375793,\n",
       " 'bert.encoder.layer.8.output.LayerNorm.weight': 0.9999893307685852,\n",
       " 'bert.encoder.layer.8.output.LayerNorm.bias': 0.9996449947357178,\n",
       " 'bert.encoder.layer.9.attention.self.query.weight': 0.9959221482276917,\n",
       " 'bert.encoder.layer.9.attention.self.query.bias': 0.9998398423194885,\n",
       " 'bert.encoder.layer.9.attention.self.key.weight': 0.996191680431366,\n",
       " 'bert.encoder.layer.9.attention.self.key.bias': 1.0,\n",
       " 'bert.encoder.layer.9.attention.self.value.weight': 0.9946290254592896,\n",
       " 'bert.encoder.layer.9.attention.self.value.bias': 0.9983386397361755,\n",
       " 'bert.encoder.layer.9.attention.output.dense.weight': 0.9941719770431519,\n",
       " 'bert.encoder.layer.9.attention.output.dense.bias': 0.9993404746055603,\n",
       " 'bert.encoder.layer.9.attention.output.LayerNorm.weight': 0.9999897480010986,\n",
       " 'bert.encoder.layer.9.attention.output.LayerNorm.bias': 0.9998794198036194,\n",
       " 'bert.encoder.layer.9.intermediate.dense.weight': 0.995162308216095,\n",
       " 'bert.encoder.layer.9.intermediate.dense.bias': 0.9995225667953491,\n",
       " 'bert.encoder.layer.9.output.dense.weight': 0.9960784912109375,\n",
       " 'bert.encoder.layer.9.output.dense.bias': 0.9996520280838013,\n",
       " 'bert.encoder.layer.9.output.LayerNorm.weight': 0.9999898076057434,\n",
       " 'bert.encoder.layer.9.output.LayerNorm.bias': 0.9992066621780396,\n",
       " 'bert.encoder.layer.10.attention.self.query.weight': 0.9968711137771606,\n",
       " 'bert.encoder.layer.10.attention.self.query.bias': 0.9998626708984375,\n",
       " 'bert.encoder.layer.10.attention.self.key.weight': 0.9967367649078369,\n",
       " 'bert.encoder.layer.10.attention.self.key.bias': 0.9999998807907104,\n",
       " 'bert.encoder.layer.10.attention.self.value.weight': 0.9958378672599792,\n",
       " 'bert.encoder.layer.10.attention.self.value.bias': 0.9945948123931885,\n",
       " 'bert.encoder.layer.10.attention.output.dense.weight': 0.9949144124984741,\n",
       " 'bert.encoder.layer.10.attention.output.dense.bias': 0.9976449608802795,\n",
       " 'bert.encoder.layer.10.attention.output.LayerNorm.weight': 0.9999893307685852,\n",
       " 'bert.encoder.layer.10.attention.output.LayerNorm.bias': 0.9997187256813049,\n",
       " 'bert.encoder.layer.10.intermediate.dense.weight': 0.9957484602928162,\n",
       " 'bert.encoder.layer.10.intermediate.dense.bias': 0.999555230140686,\n",
       " 'bert.encoder.layer.10.output.dense.weight': 0.9965755939483643,\n",
       " 'bert.encoder.layer.10.output.dense.bias': 0.9996879696846008,\n",
       " 'bert.encoder.layer.10.output.LayerNorm.weight': 0.9999895691871643,\n",
       " 'bert.encoder.layer.10.output.LayerNorm.bias': 0.9995040893554688,\n",
       " 'bert.encoder.layer.11.attention.self.query.weight': 0.997169017791748,\n",
       " 'bert.encoder.layer.11.attention.self.query.bias': 0.999872088432312,\n",
       " 'bert.encoder.layer.11.attention.self.key.weight': 0.996776282787323,\n",
       " 'bert.encoder.layer.11.attention.self.key.bias': 0.9999999403953552,\n",
       " 'bert.encoder.layer.11.attention.self.value.weight': 0.9966844916343689,\n",
       " 'bert.encoder.layer.11.attention.self.value.bias': 0.9883481860160828,\n",
       " 'bert.encoder.layer.11.attention.output.dense.weight': 0.9958602786064148,\n",
       " 'bert.encoder.layer.11.attention.output.dense.bias': 0.9945906400680542,\n",
       " 'bert.encoder.layer.11.attention.output.LayerNorm.weight': 0.9999868273735046,\n",
       " 'bert.encoder.layer.11.attention.output.LayerNorm.bias': 0.9994137287139893,\n",
       " 'bert.encoder.layer.11.intermediate.dense.weight': 0.9955733418464661,\n",
       " 'bert.encoder.layer.11.intermediate.dense.bias': 0.9991132020950317,\n",
       " 'bert.encoder.layer.11.output.dense.weight': 0.9955853819847107,\n",
       " 'bert.encoder.layer.11.output.dense.bias': 0.9986172318458557,\n",
       " 'bert.encoder.layer.11.output.LayerNorm.weight': 0.9999741315841675,\n",
       " 'bert.encoder.layer.11.output.LayerNorm.bias': 0.9983634352684021,\n",
       " 'bert.pooler.dense.weight': 0.9920661449432373,\n",
       " 'bert.pooler.dense.bias': 0.9975153803825378,\n",
       " 'classifier.weight': -0.071159727871418,\n",
       " 'classifier.bias': -0.9999999403953552}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{n: comparer.mean_similarity(n) for n in comparer.parameters.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
